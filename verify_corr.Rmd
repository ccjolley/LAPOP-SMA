---
title: "Verify correlations"
author: "Craig"
date: "12 December 2015"
output: html_document
---

Rather than re-calculating all of the indices here, we've got the code to do this stashed in a separate R file.

``` {r}
source('make_indices.R')
library(plyr)
library(MASS)
```

To systematically explore all possible correlations with our fear index, we first need to see which haven't been accounted for in one of our other composite indices.

```{r}
n_fear_more <- c(fear_common,'vic40','vic41','vic43','vic45','fear6f','fear6e',
                 'elsdiso18','elsdiso19','vicbar7f')
n_ca_common <- c('cp5','cp7','cp8','cp13','cp20')
n_ca_more <- c(n_ca_common,'honcp22','honcp21a','cp21')
n_pv_gtm <- c('pv1','pv2a','pv2b','pv2c','pv2d','pv2e','pv2f',
            'pv2g','pv2h','pv2i','pv2j','pv2k')
n_ex_common <- c('exc2','exc6','exc20','exc11','exc13','exc14',
               'exc15','exc16','exc7')
n_tr_more <- c(tr_common,'pr4','m1','b11','esb48','epp1','epp3','pr4',
             'epn3a','epn3b','epn3c','b11','b37','b14','b15','b19',
             'b46','honb51','venb11','venhonb51',
             'venhonvb10','epp1','epp3','aoj18')
n_w_more <- c(w_common,'inf3a')
n_aut_hnd <- c('dem2','dem11','aut1','jc13','jc10','jc15a',
             'jc16a','honjc17')
n_aut_common <- c('dem2','dem11','jc13','jc10','jc15a')
n_geo_more <- c('pais','estratopri','estratosec','upm','prov','municipio',
              'cluster','tamano','hondistrito')
n_dont_use <- c('idnum','fecha','wt','uniq_id','nationality','vb3n','vb11',
              'leng1')

used <- unique(c(n_fear_more,n_ca_more,n_pv_gtm,n_ex_common,n_tr_more,
                 n_w_more,crit_common,n_aut_hnd,n_geo_more,n_dont_use))

unused_common <- names(lapop.2014.all)[!(names(lapop.2014.all) %in% used)]
unused_gtm <- names(lapop.2014.GTM)[!(names(lapop.2014.GTM) %in% used) & 
                                    !(names(lapop.2014.GTM) %in% unused_common)]
unused_slv <- names(lapop.2014.SLV)[!(names(lapop.2014.SLV) %in% used) & 
                                      !(names(lapop.2014.SLV) %in% unused_common)]
unused_hnd <- names(lapop.2014.HND)[!(names(lapop.2014.HND) %in% used) & 
                                      !(names(lapop.2014.HND) %in% unused_common)]
# common questions with country-specific answers
addback <- c('vb3n','vb11','leng1')
unused_gtm <- c(unused_gtm,addback)
unused_slv <- c(unused_slv,addback)
unused_hnd <- c(unused_hnd,addback)
```

We now have a list of unused variables that are common to all three countries, as well as a list of the unique unused variables for each country. Next, we need to categorize these variables as binary, ordered, or unordered categorical.

```{r}
# Assume a function is binary if only two responses are present
is_binary <- function(data,var) {
  u <- unique(data[,var])
  length(u[u<888888]) == 2
}

bin_common <- unused_common[sapply(unused_common,function(x) 
  is_binary(lapop.2014.all,x))]
bin_gtm <- unused_gtm[sapply(unused_gtm,function(x) 
  is_binary(lapop.2014.GTM,x))]
bin_slv <- unused_slv[sapply(unused_slv,function(x) 
  is_binary(lapop.2014.SLV,x))]
bin_hnd <- unused_hnd[sapply(unused_hnd,function(x) 
  is_binary(lapop.2014.HND,x))]

# Note that, while the indicators vb3n, vb11, and leng1 are used in all three
# countries, the answers are country-specific and shouldn't be used as 
# regional indicators.
unord_common <- c('idiomaq','a4','vic2','vic2aa','aoj22','env1','vb1',
                  'vb4new','vb101','vb20','for1n','for4',
                  'for5','q3c','ocup4a','ocup1a','q11n','etid')
ord_common <- unused_common[!(unused_common %in% bin_common) &
                            !(unused_common %in% unord_common)]
unord_gtm <- c('aoj21','chipart107n','parclien','guaetid2n','leng4','vb3n','vb11','leng1')
ord_gtm <- unused_gtm[!(unused_gtm %in% bin_gtm) &
                        !(unused_gtm %in% unord_gtm)]
unord_slv <- c('esexc16a','elsvb48','pr1','vb3n','vb11','leng1')
ord_slv <- unused_slv[!(unused_slv %in% bin_slv) &
                        !(unused_slv %in% unord_slv)]
unord_hnd <- c('dst1','vb3n','vb11','leng1')
ord_hnd <- unused_hnd[!(unused_hnd %in% bin_hnd) &
                              !(unused_hnd %in% unord_hnd)]
```

The appopriate method for finding correlations will be different for each of these three types of variables. I've defined three functions that take the same inputs and produce similar outputs, so that all can be combined and compared at the end.

Note that all of the functions below set the p-value cutoff, by default, to `1/ncol(data)` This is appropriate in cases (like this one) where we're looking at a large number of variables -- if we have more variables then we're more likely to observe spurious correlations so we need to be stricter. 

```{r}
bin_cor <- function(data,var1,var2,cutoff=0) {
  # Determine the correlation between a variable var1 and a binary variable 
  # var2. This uses a Fisher test conditioned on the values of var2, and will
  # be applicable if var1 is continuous (i.e. one of our composite indices).
  res = data.frame(var=character(),est=numeric(),pval=numeric(),
                   stringsAsFactors=FALSE)
  if (var1 != var2) {
    if (cutoff == 0) {
      cutoff <- 1 / ncol(data)
    }
    tmp <- data.frame(v1=data[,var1],v2=data[,var2])
    is.na(tmp[tmp>800000]) <- TRUE
    tmp$v2 <- tmp$v2 - min(tmp$v2,na.rm=TRUE) # convert to 0-1 scale
    if (sum(tmp$v2==0,na.rm=TRUE) > 1 & sum(tmp$v2==1,na.rm=TRUE) > 1) {
      tt <- t.test(tmp$v1[tmp$v2==0],tmp$v1[tmp$v2==1])
      if (tt$p.value < cutoff) {
        res=data.frame(var=var2,est=tt$estimate[2]-tt$estimate[1],pval=tt$p.value,
                       stringsAsFactors=FALSE)
      }
    }
  }
  res
}

ord_cor <- function(data,var1,var2,cutoff=0) {
  # Determine the correlation between two ordered variables, var1 and var2. 
  # This uses linear regression, and will be applicable when we're dealing
  # with ordered categorical variables or composite indices.
  # As a matter of convention, use the composite index as var1 so that the
  # output makes sense.
  res = data.frame(var=character(),est=numeric(),pval=numeric(),
                   stringsAsFactors=FALSE)
  if (var1 != var2) {
    if (cutoff == 0) {
      cutoff <- 1 / ncol(data)
    }
    tmp <- data.frame(v1=data[,var1],v2=data[,var2])
    is.na(tmp[tmp>800000]) <- TRUE
    reg <- lm(v1 ~ v2,data=tmp)
    p <- summary(reg)$coefficients[2,4]
    if (p < cutoff) {
      res=data.frame(var=var2,est=summary(reg)$coefficients[2,1],pval=p,
                     stringsAsFactors=FALSE)
    }
  }
  res
}

unord_cor <- function(data,var1,var2,cutoff=0) {
  # Determine the correlation between an ordered variable var1 and an unordered
  # categorical variable var2. Do this by creating a binary variable for each
  # possible value of var2 and calling bin_cor().
  vals <- na.omit(unique(data[data[,var2] < 800000,var2]))
  if (cutoff == 0) {
    cutoff <- 1 / ncol(data)
  }
  tmp <- data.frame(v1=data[,var1])
  is.na(tmp[tmp>800000]) <- TRUE
  for (x in vals) {
    tmp[,paste(var2,x,sep='_')] <- as.numeric(data[,var2] == x)
  }
  ldply(names(tmp),function(x) bin_cor(tmp,'v1',x,cutoff))
}
```

**Region-wide**

Now we're going to look at the region-wide correlations. First, define a data frame that will contain all of the variables that were not used to generate composite indices, along with the composite indices.

```{r}
a <- lapop.2014.all[,unused_common]
is.na(a[a>800000]) <- TRUE
# add in all of the composite indices
a$fear_idx <- fear_all
a$ca_idx <- ca_all
a$tr_idx <- tr_all
a$w_idx <- w_all
a$crit_idx <- crit_all
a$aut_idx <- aut_all
idxs <- c('fear_idx','ca_idx','tr_idx','w_idx','crit_idx','aut_idx')
```

Next, we'll use the functions defined above to get all of our correlations. We'll keep those with p-values below the cutoff of `r 1/ncol(a)`.

While we have a list of which values of unordered categorical variables are significantly correlated with the fear index, the variables aren't formatted in a way that will be useful for multiple regression. We'll do this by creating dummy variables, with the same names as the `var` column in `cor_all`. (For example, `ocup1a_4` for `ocup1a == 4`.)

```{r}
cor_data <- function(d,bin_vars,ord_vars,idx_vars,unord_vars) {
  # takes a data frame d with all of the variabels that are to be correlated
  # with the fear index, and returns a new data frame with all of the 
  # high-correlation variables, including dummy variables
  cor_bin <- ldply(bin_vars, function(x) bin_cor(d,'fear_idx',x))
  cor_ord <- ldply(ord_vars, function(x) ord_cor(d,'fear_idx',x))
  cor_idx <- ldply(idx_vars, function(x) ord_cor(d,'fear_idx',x))
  cor_unord <- ldply(unord_vars, function(x) unord_cor(d,'fear_idx',x))
  cor_all <- rbind(cor_bin,cor_ord,cor_unord,cor_idx)
  cor_all <- cor_all[order(cor_all$pval),]
  unord_vars <- ldply(cor_unord$var, function(x)
    data.frame(var=strsplit(x,'_')[[1]][1],
               val=as.numeric(strsplit(x,'_')[[1]][2]),
               str=x,
               stringsAsFactors=FALSE))
  for (i in 1:nrow(unord_vars)) {
    d[,unord_vars$str[i]] <- as.numeric(d[,unord_vars$var[i]] == unord_vars$val[i])
  }
  res <- d[,cor_all$var]
  res$fear_idx <- d$fear_idx  
  res
}

a2 <- cor_data(a,bin_common,ord_common,idxs,unord_common)
```

One thing that can cause trouble in multiple regression is missing values -- we can only include rows in our dataframe that have a non-NA value for all of the variables compared. This means that as we add in more and more variables, we throw out more and more data, and our final results can be biased. We'll get around this by using multiple imputation. We'll need to create a predictor matrix (named `pm`) to account for the fact that we don't want to be using our fear index to impute values of the other variables -- this would be sort of circular logic!

```{r}
pm <- 1 - diag(ncol(a2))
pm[,which(names(a2)=='fear_idx')] <- 0
b <- mice(a2,printFlag=F,predictorMatrix=pm)
```

We can get to a decent set of variables using stepwise regression. What we'll do is run backward stepwise regression on each imputed dataset and keep only the ones that appear for all five sets. One can get pretty much the exact same result using forward regression (I checked).

```{r}
get_vars <- function(x) {
  # gets variables that appear consistently in stepwise regression
  # x should be an object returned by MICE
  lm1 <- lm(fear_idx ~ .,data=na.omit(complete(x,1)))
  lm2 <- lm(fear_idx ~ .,data=na.omit(complete(x,2)))
  lm3 <- lm(fear_idx ~ .,data=na.omit(complete(x,3)))
  lm4 <- lm(fear_idx ~ .,data=na.omit(complete(x,4)))
  lm5 <- lm(fear_idx ~ .,data=na.omit(complete(x,5)))
  step1 <- stepAIC(lm1,trace=F) 
  step2 <- stepAIC(lm2,trace=F) 
  step3 <- stepAIC(lm3,trace=F) 
  step4 <- stepAIC(lm4,trace=F)
  step5 <- stepAIC(lm5,trace=F) 
  counts <- as.data.frame(table(c(names(coef(step1)),names(coef(step2)),
                                  names(coef(step3)),names(coef(step4)),
                                  names(coef(step5)))),stringsAsFactors=F)
  counts[counts$Freq==5,'Var1']
}

get_vars(b)

b.reg2 <- with(data=b,exp=lm(fear_idx ~ a4_5 + aoj22_1 + aut_idx + ca_idx + 
                               clien1n + d6 + ed2 + eff2 + for1n_7 + for4_4 + 
                               for5_6 + for6 + it1 + mil10c + ocup4a_3 + 
                               pol1 + pole2n + q3c_12 + q3c_5 + sd3new2 + tr_idx + 
                               ur + vb20_4 + w14a + www1))

lm_plot <- function(x,orig) {
  # x must be the output from a multiple regression on MICE output
  # orig must be the original, unimputed dataset
  s <- summary(pool(x))
  plotme <- data.frame(s[-1,c(1,5)])
  plotme$log_p <- -log10(plotme[,2])
  m <- max(plotme$log_p[plotme$log_p < Inf])
  plotme$log_p[plotme$log_p > m] <- 1.1*m
  scale <- sapply(rownames(plotme),
                  function(x) max(orig[,x],na.rm=TRUE) - min(orig[,x],na.rm=TRUE))
  scale[scale %% 1 > 0] <- 1 # don't rescale composite indices
  plotme$est <- plotme$est * scale
  plotme$label <- rownames(plotme)
  ggplot(data=plotme,aes(x=log_p,y=est,color=est,label=label)) +
    geom_point(size=20,alpha=0.2) +
    geom_text(color='black') +
    geom_segment(x=-log10(0.01),xend=-log10(0.01),
                 y=1.2*min(plotme$est),yend=0.95*max(plotme$est),color='red') +
    annotate("text",x=-log10(0.01)+0.2,y=max(plotme$est),label='p=0.01',
             color='red') +
    geom_segment(x=-log10(0.05),xend=-log10(0.05),
                 y=1.2*min(plotme$est),yend=0.95*max(plotme$est),color='blue') +
    annotate("text",x=-log10(0.05)-0.2,y=max(plotme$est),label='p=0.05',
             color='blue') +
    scale_color_gradientn(colours=rainbow(4)) +
    theme_classic() +
    theme(legend.position='none') +
    xlab('Significance (-log(p))') +
    ylab('Influence on fear index')
}

lm_plot(b.reg2,a2)
```

Variable  |Description                                    |Effect
----------|-----------------------------------------------|-------
`it1`     |Interpersonal trust                            |Less trust = more fear
`ur`      |Urbanization                                   |Urban = more fear  
`tr_idx`  |Trust in government                            |Less trust = more fear
`ca_idx`  |Community activity                             |More involvement = more fear
`q3c = 5` |Evangelical/Protestant                         |More fearful
`aut_idx` |Authoritarianism                               |More authoritarian = more fear
`pole2n`  |Satisfaction with police performance           |Less satisfied = more fearful
`pol1`    |Interest in politics                           |More interest = more fear
`for6`    |Influence of China in country                  |More influence = more fear
`aoj22=1` |Reduce crime via preventative measures         |Less fearful
`a4 = 5`  |Believes crime is the most serious problem     |More fearful
`mil10c`  |Trustworthiness of Iranian government          |More trustworthy = more fear
`clien1n` |Knows someone offered benefit for vote         |Yes = more fear
`ocup4a=3`|Actively looking for a job                     |More fearful
`q3c = 12`|Jehovah's Witnesses                            |More fearful
`www1`    |Internet usage                                 |Frequent = more fear
`w14a`    |Abortion justified when mother's health at risk|Yes = more fear
`sd3new2` |Satisfaction with public schools               |Dissatisfaction = more fear
`ed2`     |Education level of mother                      |More educated = more fear
`vb20 = 4`|Plans to leave ballot blank in next election   |More fearful
`d6`      |Approval of same-sex marriage                  |Approving = more fear 
`for1n=7` |Most influential country is Mexico             |More fearful

```{r}
geo <- c('pais','estratopri','estratosec','prov','municipio')
my_geo <- lapop.2014.all[,geo]
my_geo$muni_uniq <- 10000*my_geo$pais + my_geo$municipio
my_geo$fear <- fear_all
muni_avg <- ddply(my_geo,~muni_uniq,summarize,x=mean(fear))
my_geo$muni_avg <- muni_avg$x[match(my_geo$muni_uniq,muni_avg$muni_uniq)]

b.reggeo <- with(data=b,exp=lm(fear_idx ~ a4_5 + aoj22_1 + aut_idx + ca_idx + 
                               clien1n + d6 + ed2 + eff2 + for1n_7 + for4_4 + 
                               for5_6 + for6 + it1 + mil10c + ocup4a_3 + 
                               pol1 + pole2n + q3c_12 + q3c_5 + sd3new2 + tr_idx + 
                               ur + vb20_4 + w14a + www1 + my_geo$muni_avg))
s_geo <- summary(pool(b.reggeo))
plotme$geo_est <- s_geo[c(-1,-27),1]
plotme$geo_logp <- -log10(s_geo[c(-1,-27),5])
m <- max(plotme$geo_logp[plotme$geo_logp < Inf])
plotme$geo_logp[plotme$geo_logp > m] <- 1.1*m
plotme$geo_est <- plotme$geo_est * scale
nx = rep(0,nrow(plotme))
ny = rep(0,nrow(plotme))
ggplot(data=plotme,aes(x=geo_logp,y=geo_est,color=geo_est,
                       label=rownames(plotme))) +
  geom_point(size=20,alpha=0.2) +
  geom_segment(aes(x=plotme$log_p,y=plotme$est,
                   xend=plotme$geo_logp,yend=plotme$geo_est,
                   color=geo_est)) +
  geom_text(color='black',aes(x=geo_logp+nx, y=geo_est+ny)) +
  geom_segment(x=-log10(0.01),xend=-log10(0.01),
               y=1.2*min(plotme$est),yend=0.95*max(plotme$est),color='red') +
  annotate("text",x=-log10(0.01)+0.2,y=max(plotme$est),label='p=0.01',
           color='red') +
  geom_segment(x=-log10(0.05),xend=-log10(0.05),
               y=1.2*min(plotme$est),yend=0.95*max(plotme$est),color='blue') +
  annotate("text",x=-log10(0.05)-0.2,y=max(plotme$est),label='p=0.05',
           color='blue') +
  scale_color_gradientn(colours=rainbow(4)) +
  theme_classic() +
  theme(legend.position='none') +
  xlab('Significance (-log(p))') +
  ylab('Influence on fear index')
#TODO: Factor this out into a function as well

```

When we include the municipality averages in our multiple correlation, we're asking about the factors that make a person more fearful than others in their community. The straight lines attached to each circle illustrate how much they moved from the previous plot -- for example, `tr_idx` became dramatically less significant while `mil10c` hardly moved at all. This suggests that people's trust in their own government (`tr_idx`) correlates strongly with their municipality, while views on the Iranian government (`mil10c`) serve more to differentiate people within the same community and actually become more significant. In general, most variables have a smaller estimated influence, but most significant variables remain significant -- some actually even increase. This means that we're measuring more than just attributes of places; these variables are telling us about people within heterogeneous places.

The following variables lost enough significance when we included municipality-level fear averages that they are no longer significant at the p=0.05 level: `d6`, `ed2`, `for1n=7`, `sd3new2`, `vb20=4`, and `w14a`.

In addition, `for6` and `q3c = 12` were previously significant at the p=0.01 level and are now only significant at the p=0.05 level.

# Guatemala #

Next, let's see if any of the Guatemala-specific variables are interesting. 

```{r}
g <- lapop.2014.GTM[,c(unused_common,unused_gtm)]
is.na(g[g>800000]) <- TRUE
g$fear_idx <- fear_gtm
g$ca_idx <- ca_all[lapop.2014.all$pais==2] # there is no ca_gtm
g$tr_idx <- tr_gtm
g$w_idx <- w_gtm
g$crit_idx <- crit_all[lapop.2014.all$pais==2]
g$aut_idx <- aut_all[lapop.2014.all$pais==2]
g$pv_idx <- pv_gtm
idxs <- c('fear_idx','ca_idx','tr_idx','w_idx','crit_idx','aut_idx','pv_idx')

g2 <- cor_data(g,c(bin_common,bin_gtm),c(ord_common,ord_gtm),idxs,
               c(unord_common,unord_gtm))
```

We definitely see a few variables that weren't on the menu before; some of these we might want to add into the indices we have.

```{r}
pm_g <- 1 - diag(ncol(g2))
pm_g[,which(names(g2)=='fear_idx')] <- 0
g_imp <- mice(g2,printFlag=F,predictorMatrix=pm_g)
```

Let's cut right to the chase and use stepwise regression on our multiply-imputed data:

```{r}
get_vars(g_imp)

g.reg <- with(data=g_imp,exp=lm(fear_idx ~ a4_27 + a4_5 + aoj21_1 + aoj21_2 + 
                                  aoj21_6 + aoj21_7 + aoj21_8 + aut_idx + 
                                  crit_idx + d6 + dvw1 + etid_2 + guaetid2n_1 + 
                                  it1 + leng4_1 + leng4_2 + mil10a + per9 + 
                                  pn4 + pol1 + pole2n + pr3a + pv_idx + pv3 + 
                                  q3c_2 + tr_idx + ur + vb20_4 + vic52n + w_idx))

lm_plot(g.reg,g2)
```

Variable         |Description                                  |Effect
-----------------|---------------------------------------------|------------------------
`ur`             |Urbanizaton                                  |Urban = more fearful
`aoj21 = 8`     |Biggest threat = none of the above           |Less fearful
`aoj21 = 2`     |Gangs are biggest threat to security         |More fearful
`leng4 = 1`     |Parents only speak Spanish (not indigenous)  |More fearful
`it1`            |Interpersonal trust                          |Less trust = more fear
`pv_idx`         |Political violence index                     |More violence = more fear
`a4 = 5`        |Crime the biggest problem                    |More fearful
`tr_idx`         |Trust in government index                    |Less trust = more fear
`vb20 = 4`      |Plans to vote but leave ballot blank         |More fear
`aut_idx`        |Authoritarianism index                       |More authoritarian = more fear
`pv3`            |Believes violence was used in 2015 elections |More belief = more fear
`dvw1`           |Husband can hit wife if she neglects chores  |Less approving = more fear
`pr3a`           |Pirating DVDs results in punishment?         |Yes = more fear
`aoj21 = 7`      |Biggest threat to security = other           |More fearful
`vb20 = 3`       |Plans to vote against current admin.         |Less fearful
`mil10a`         |Trustworthiness of Chinese government        |Less trust = more fear
`guaetid2n == 1` |Ethnic group = AchÃ­                          |Less fearful
`d6`             |Approval of same-sex marriage                |More approving = more fear
`q3c = 2`        |Mainline Protestant (not Evangelical)        |Less fearful
`crit_idx`       |Sympathy with gov critics                    |More sympathy = more fear
`aoj21 = 6`      |Biggest threat to security = common criminals|More fearful
`pn4`            |Satisfaction with democracy                  |More dissatisfied = more fear
`w_idx`          |Wealth index                                 |More wealth = less fear

We can generalize to a few trends:
- Ethnicity: Spanish-speaking Ladinos seem to be more fearful than people with indigenous languages and identities.
- People with more "liberal" attitudes about same-sex marriage and spousal abuse are more fearful.
- At the same time, people with more authoritarian political attitudes and less satisfaction with democracy are more fearful. Is this a contradiction?
- People who see strong US influence are more fearful, but so are people who see strong Chinese influence. Is this a contradiction?
- People who consider themselves emotionally stable are actually *more* fearful. What's going on here?

TODO: Same geographic analysis we saw at the regional level.

# El Salvador #

```{r}
s <- lapop.2014.SLV[,c(unused_common,unused_slv)]
is.na(s[s>800000]) <- TRUE
s$fear_idx <- fear_slv
s$ca_idx <- ca_all[lapop.2014.all$pais==3] # there is no ca_gtm
s$tr_idx <- tr_slv
s$w_idx <- w_slv
s$crit_idx <- crit_all[lapop.2014.all$pais==3]
s$aut_idx <- aut_all[lapop.2014.all$pais==3]
idxs <- c('fear_idx','ca_idx','tr_idx','w_idx','crit_idx','aut_idx')

s2 <- cor_data(s,c(bin_common,bin_slv),c(ord_common,ord_slv),idxs,
               c(unord_common,unord_slv))

pm_s <- 1 - diag(ncol(s2))
pm_s[,which(names(s2)=='fear_idx')] <- 0
s_imp <- mice(s2,printFlag=F,predictorMatrix=pm_s)
```

Let's cut right to the chase and use stepwise regression on our multiply-imputed data:

```{r}
get_vars(s_imp)

s.reg <- with(data=s_imp,exp=lm(fear_idx ~  aut_idx + ca_idx + clien1n + ed + 
                                  ed2 + elsvb48_11 + elsvb55a + elsvb55c + 
                                  env1_2 + info1 + infra2 + it1 + np1 + 
                                  ocup4a_1 + ocup4a_3 + pol1 + pole2n + pr1_3 + 
                                  q10a + q11n_6 + q3c_5 + sd6new2 + sexi + 
                                  tr_idx + ur))
lm_plot(s.reg,s2)
```

Variable         |Description                                     |Effect
-----------------|------------------------------------------------|------------------------------
`it1`            |Interpersonal trust                             |Less trust = more fear
`ur`             |Urbanizaton                                     |Urban = more fearful
`sexi`           |Interviewer sex                                 |Female = more fearful
`pole2n`         |Satisfaction with police performance            |Dissatisfied = more fearful
`elsvb55c`       |Uses newspaper as info source for voting        |Yes = more fearful
`sd6new2`        |Satisfaction with public health services        |Dissatisfied = more fearful
`pol1`           |Interest in politics                            |More interest = more fear
`pr1 = 3`        |Borrowed or shared home (not owned/rented)      |More fearful
`q3c = 5`        |Evangelical/Protestant                          |More fearful
`info1`          |Heard of the Law of Access to Public Information|Yes = more fearful
`aut_idx`        |Authoritarianism index                          |More authoritarian = more fear
`tr_idx`         |Trust in government index                       |Less trust = more fear
`elsvb48 = 11`   |Didn't vote in 2012 legislative elections       |Less fearful
`infra2`         |Fire department response time                   |Short = more fear
`elsvb55a`       |Uses radio as info source for voting            |Yes = more fearful
`q10a`           |Receives remittances                            |Yes = more fear
`clien1n`        |Knows someone offered benefit for vote          |Yes = more fear
`ed2`            |Mother's education level                        |Higher = more fear
`ocup4a = 1`     |Employed                                        |More fearful
`np1`            |Attended a municipal meeting                    |Yes = more fearful

**Honduras**

```{r}
h <- lapop.2014.HND[,c(unused_common,unused_hnd)]
is.na(h[h>800000]) <- TRUE
h$fear_idx <- fear_hnd
h$ca_idx <- ca_hnd 
h$tr_idx <- tr_hnd
h$w_idx <- w_hnd
h$crit_idx <- crit_hnd
h$aut_idx <- aut_hnd
idxs <- c('fear_idx','ca_idx','tr_idx','w_idx','crit_idx','aut_idx')

h2 <- cor_data(h,c(bin_common,bin_hnd),c(ord_common,ord_hnd),idxs,
               c(unord_common,unord_hnd))

pm_h <- 1 - diag(ncol(h2))
pm_h[,which(names(h2)=='fear_idx')] <- 0
h_imp <- mice(h2,printFlag=F,predictorMatrix=pm_h)

get_vars(h_imp)

h.reg <- with(data=h_imp,exp=lm(fear_idx ~ aut_idx + b20 + clien1na + coer1 + 
                                  ico2 + it1 + mil10c + ocup4a_3 + per4 + 
                                  pole2n + pr3e + prot3 + sd3new2 + sexi + 
                                  tr_idx + ur))

lm_plot(h.reg,h2)
```

Variable         |Description                                     |Effect
-----------------|------------------------------------------------|------------------------------
`ur`             |Urbanizaton                                     |Urban = more fearful
`ico2`           |National police patrols the neighborhood        |More patrols = more fear
`it1`            |Interpersonal trust                             |Less trust = more fear
`pole2n`         |Satisfaction with police performance            |Dissatisfied = more fearful
`sexi`           |Interviewer sex                                 |Male = more fearful
`mil10c`         |Trustworthiness of Iranian government           |More trustworthy = more fear
`pr3e`           |Building/renovating necessitates bribe          |More likely = more fear
`aut_idx`        |Authoritarianism index                          |More authoritarian = more fear
`tr_idx`         |Trust in government index                       |Less trust = more fear
`coer1`          |Receive receipts from neighborhood stores       |More often = more fear
`sd3new2`        |Satisfaction with public schools                |Dissatisfaction = more fear
`clien1na`       |Offered benefit for vote                        |Yes = more fear
`ocup4a=3`       |Actively looking for a job                      |More fearful
`per4`           |Anxious personality                             |Yes = more fear
`prot3`          |Participated in a protest                       |Yes = more fear
`b20`            |Trust in Catholic Church                        |Less trust = more fear

