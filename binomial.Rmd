---
title: "Binomial variables in LAPOP"
author: "Craig Jolley"
date: "September 28, 2015"
output: html_document
---

Binomial variables are those that can take on two values: 0/1, yes/no, male/female, etc. A *lot* of the Americas Barometer variables are of this type.

Here, we'll focus on one example: indicator `vic40` (Out of fear of being a crime victim, in the last 12 months have you limited the places where you go shop?). This variable takes on the following values:

- 1 = Yes
- 2 = No
- 888888 = Don't know
- 988888 = No response

Before going further, let's load the necessary libraries:

```{r message=FALSE}
library(ggplot2) # needed for plotting
library(stringr) # also needed for plot
library(googleVis) # use this for interactive maps
library(plyr)
library(ISOcodes) # need this for department names
```

For now, focus on Honduras in 2014. Assuming that you've already downloaded all of the Americas Barometer data (look [here](https://github.com/ccjolley/LAPOP-SMA/blob/master/load_lapop.R) if you haven't), we can load it into an R data frame:

```{r}
lapop.2014.HND <- read.csv('../2014-HND.csv')
```

The easiest thing to do is look at the average. We need to make sure that we only look at valid yes/no responses; our average will be meaningless otherwise. The easy way to do this is to create a copy of our data and remove the useless entries. If you want to do this with a different dataset, just replace `vic40` below with a different indicator.

```{r}
my_data <- lapop.2014.HND$vic40[lapop.2014.HND$vic40<3] # keep only entries with value < 3
mean(my_data==1)
```

There are two things going on in that statement. `vic40==1` creates a string of TRUE/FALSE values, telling us whether the answer was equal to 1. Taking the mean of this tells us what fraction of people responded 'yes' -- about 34%.

Averages can be misleading -- they didn't ask everyone, and so the real average might not be exactly 34%. We can see what the likely range of values is by using an exact binomial test:

```{r}
binom.test(sum(my_data==1),length(my_data))
```

This tells us that, out of 1558 people who answered the question, 531 said "yes", so the population average (what we would get if we really asked everybody) has a 95% chance of being between 31.7% and 36.5%.

Just for fun, we can see what would happen if the LAPOP team had only asked 100 people:

```{r}
binom.test(sum(head(my_data,100)==1),100)
```

If we only had the first 100 survey responses, we can only be confident that the population average is between 21.2% and 40%. Asking more people matters!

Suppose we want to make a snazzy bar chart (because pie charts are so 2004). I'm making this chart using **ggplot**, which is a really powerful graphics package for R. The syntax can be sort of intimidating; what I do is to keep a "recipe collection" of plots that have looked nice in the past so that I can just make small changes as needed. If you change which indicator you're looking at, you might need to adjust things a little to keep it looking nice.

```{r}
f <- data.frame(my_data)
names(f) <- 'ans'
yes_text <- paste('Yes: ',round(mean(my_data==1)*100,digits=1),'%',sep='') # Label for 'yes' bar
no_text <- paste('No: ',round(mean(my_data==2)*100,digits=1),'%',sep='') # Label for 'no' bar
q_text <- 'Out of fear of being a crime victim, in the last 12 months have you limited the places where you go shop?'
q_y <- max(sum(my_data==1),sum(my_data==2)) # How high up should the question text be?
offset=length(my_data)*0.05 # Move labels down a bit from the top of bars
ggplot(f,aes(factor(ans,labels=c('Yes','No')))) + 
  geom_bar(fill='goldenrod') +
  annotate('text',label=yes_text,      # add 'yes' label
           size=8,x=1,y=sum(my_data==1)-offset,hjust=0.5,vjust=0) +
  annotate('text',label=no_text,       # add 'no' label
           size=8,x=2,y=sum(my_data==2)-offset,hjust=0.5,vjust=0) +
  annotate('text',label=str_wrap(q_text,width=32),  # add question text
           size=5,x=0.5,y=q_y,hjust=0,vjust=1) +
  theme_classic() +
  theme(text=element_text(size=20),
        axis.title.y=element_blank(),
        axis.title.x=element_blank(),
        axis.text.x=element_blank(),
        axis.ticks.x=element_blank()) 
```

That's all nice, but there's probably more we can do with this indicator. For example, we can test for correlations with other binomial variables. For example, are men or women more likely to change their shopping patterns? We can do this using [Fisher's exact test](http://www.cookbook-r.com/Statistical_analysis/Frequency_tests/).

We'll want to keep only the observations that have valid answers for both `vic40` and `sex`:

```{r}
my_data2 <- lapop.2014.HND[,c('vic40','sex')]
my_data2 <- my_data2[my_data2$vic40<3 & my_data2$sex<3,]
```

Now let's put them in a contingency table, and run a Fisher test:

```{r}
ct <- table(my_data2$vic40,my_data2$sex)
fisher.test(ct)
```

Our odds ratio is very close to 1, and our p value is > 0.05, so it's likely that there's no real difference in how men and women change their shopping behavior in response to fear of crime. 

We could also see if being a victim of crime makes people more likely to change their shopping habits out of fear, by looking at the `vic1ext` indicator:

```{r}
my_data3 <- lapop.2014.HND[,c('vic40','vic1ext')]
my_data3 <- my_data3[my_data3$vic40<3 & my_data3$vic1ext<3,]
ct <- table(my_data3$vic40,my_data3$vic1ext)
fisher.test(ct)
```

Now we have an odds ratio close to 3 -- being a victim of crime makes people about 3x as likely to change their shopping habits. Our very low p-value means that this is probably a significant correlation. If you want something more visual, you could try this:

```{r}
plotme <- my_data3
plotme[plotme==2] <- 1.5
ggplot(plotme,aes(x=vic1ext,y=vic40)) + 
  geom_jitter(color='darkgreen',size=5, alpha=0.2, position = position_jitter(w = 0.2, h = 0.2)) + 
  annotate('text',label='Changed shopping',    
           size=7,x=1,y=1.8,hjust=0.5,vjust=0) +
  annotate('text',label="Didn't change",    
           size=7,x=1.5,y=1.8,hjust=0.5,vjust=0) +
  annotate('text',label="Crime victim",    
           size=7,x=0.75,y=1,hjust=1,vjust=0) +
  annotate('text',label="Non-victim",    
           size=7,x=0.75,y=1.5,hjust=1,vjust=0) +
  scale_x_continuous(limits=c(0.5,1.7)) +
  theme_classic() +
  theme(line=element_blank(),
        title=element_blank(),
        text=element_blank())
```

Now it's really obvious that most non-victims haven't changed their shopping habits, while a larger fraction of victims have changed theirs.

Where do the people who have made these changes live? I'm going to map this out using the Google Charts API, which looks like the easiest way to make interactive maps in R. For now, we'll map results by department, which are encoded in the `prov` indicator. These numeric values need to be translated into [ISO-3116-2 region codes](https://en.wikipedia.org/wiki/ISO_3166-2:HN#II-3).

```{r}
map_data <- lapop.2014.HND[,c('prov','vic40')]
map_data <- map_data[map_data$vic40<3,] # need valid vic40 responses
map_data$prov[map_data$prov==401] <- 'HN-FM' # Francisco Morazán
map_data$prov[map_data$prov==402] <- 'HN-CM' # Comayagua
map_data$prov[map_data$prov==403] <- 'HN-LP' # La Paz
map_data$prov[map_data$prov==404] <- 'HN-CR' # Cortés
map_data$prov[map_data$prov==405] <- 'HN-AT' # Atlántida
map_data$prov[map_data$prov==406] <- 'HN-CL' # Colón
map_data$prov[map_data$prov==407] <- 'HN-YO' # Yoro
map_data$prov[map_data$prov==408] <- 'HN-IB' # Islas de la Bahía
map_data$prov[map_data$prov==409] <- 'HN-CP' # Copán
map_data$prov[map_data$prov==410] <- 'HN-IN' # Intibucá
map_data$prov[map_data$prov==411] <- 'HN-LE' # Lempira
map_data$prov[map_data$prov==412] <- 'HN-OC' # Ocotepeque
map_data$prov[map_data$prov==413] <- 'HN-SB' # Santa Bárbara
map_data$prov[map_data$prov==418] <- 'HN-EP' # El Paraíso
map_data$prov[map_data$prov==419] <- 'HN-OL' # Olancho
map_data$prov[map_data$prov==420] <- 'HN-GD' # Gracias a Dios
map_data$prov[map_data$prov==421] <- 'HN-CH' # Choluteca
map_data$prov[map_data$prov==422] <- 'HN-VA' # Valle
map_data$vic40 <- 2 - map_data$vic40 # Now, 0=no, 1=yes
map_avg <- ddply(map_data,~prov,summarize,x=mean(vic40))
```

Now, let's make our map:

```{r,results='asis'}
map_avg$vic40 <- round(map_avg$x,3)
data("ISO_3166_2")
ISO_3166_2_HN <- subset(ISO_3166_2, Country %in% "HN")
ISO_3166_2_HN$prov <- ISO_3166_2_HN$Code # need matching names for join operation
joined <- join(ISO_3166_2_HN,map_avg,by="prov")[c('Code','Name','vic40')]
g <- gvisGeoChart(joined,locationvar='Code',colorvar='vic40',hovervar='Name',
                  options=list(region="HN",resolution="provinces",
                               colorAxis="{minValue: 0,  colors: ['#FFFFFF', '#2B65EC']}"))
print(g,'chart')
```

So this is OK -- it tells us which departments showed the largest and smallest average values for `vic40`. Hover over the map with your mouse to see department names and average values. Another way of visualizing this that might be useful is to figure out which departments showed values of `vic40` that are significantly above-average (according to an exact Fisher test) and highlight those.

```{r,results='asis'}
vic40gt <- function(x) {
  ct <- table(map_data$vic40,map_data$prov==x)
  ft <- fisher.test(ct)
  if (ft$p.value < 0.095 & ft$estimate > 1) {
    return(1)
  }
  return(0)
}
is.gt <- data.frame(gt=sapply(unique(map_data$prov),vic40gt))
is.gt$Code <- rownames(is.gt)
joined <- merge(is.gt,joined,by='Code')
g <- gvisGeoChart(joined,locationvar='Code',colorvar='gt',hovervar='Name',
                  options=list(region="HN",resolution="provinces",
                               colorAxis="{minValue: 0,  colors: ['#FFFFFF', '#C11B17']}"))
print(g,'chart')
```

We can also look to see which departments have below-average values of `vic40`:

```{r,results='asis'}
vic40lt <- function(x) {
  ct <- table(map_data$vic40,map_data$prov==x)
  ft <- fisher.test(ct)
  if (ft$p.value < 0.095 & ft$estimate < 1) {
    return(1)
  }
  return(0)
}
is.lt <- data.frame(lt=sapply(unique(map_data$prov),vic40lt))
is.lt$Code <- rownames(is.lt)
joined <- merge(is.lt,joined,by='Code')
g <- gvisGeoChart(joined,locationvar='Code',colorvar='lt',hovervar='Name',
                  options=list(region="HN",resolution="provinces",
                               colorAxis="{minValue: 0,  colors: ['#FFFFFF', '#3EA055']}"))
print(g,'chart')
```

So let's go back to the high-`vic40` areas. What's special about Cortes and Atlantida? Cortes contains San Pedro Sula, which is Honduras's 2nd-largest city, and Choloma, which is #3. The 4th-largest, La Ceiba, is in Atlantida. Is it possible that all we're seeing here is urbanization -- people in cities experience more crime and more shopping options, so they're more likely to change their shopping habits? First, let's see whether `vic40` correlates with the urbanization indicator, `ur` (1=urban, 2=rural).

```{r}
my_data4 <- lapop.2014.HND[,c('vic40','ur')]
my_data4 <- my_data4[my_data4$vic40<3 & my_data4$ur<3,]
ct <- table(my_data4$vic40,my_data4$ur)
fisher.test(ct)         
```

So we can be at least 95% sure that there's a relationship between `vic40` and `ur`. So is there something special about Atlantida and Cortes, or is the urban/rural split the important factor?

```{r}
my_data5 <- lapop.2014.HND[,c('vic40','ur','prov')]
my_data5$loc <- my_data5$prov == 404 | my_data5$prov == 405 # Atlantida or Cortes
my_data5 <- my_data5[my_data5$vic40<3 & my_data5$ur<3,] # make sure vic40 and ur are valid
my_data5$vic40 <- 2 - my_data5$vic40 # now 0 = no, 1 = yes
urban <- subset(my_data5,ur==1)
rural <- subset(my_data5,ur==2)
ct_urban <- table(urban$vic40,urban$loc) 
fisher.test(ct_urban)
```

So the city-dwellers of Atlantida and Cortes are more likely to change their shopping location than urban people in other parts of the country.

```{r}
ct_rural <- table(rural$vic40,rural$loc)
fisher.test(ct_rural)
```

The same doesn't hold for their rural populations -- rural residents of Atlantida and Cortes are no more likely to change their shopping habits than rural people elsewhere.

What if we turn this around? Are urban people in Atlantida and Cortes more likely to change their shopping habits than rural people in those departments?

```{r}
in_loc <- subset(my_data5,loc==1)
ct_in <- table(in_loc$vic40,in_loc$ur)
fisher.test(ct_in)
```

This relationship is statistically significant. Note that the odds ratio is less than 1: this is because `vic40` takes values of 0=no, 1=yes, while `ur` takes 1=urban, 2=rural. So an odds ratio less than 1 means that an increase in `vic40` will tend to a decrease in `ur`, and vice versa. Is this relationship also true outside Atlantida and Cortes?

```{r}
out_loc <- subset(my_data5,loc==0)
ct_out <- table(out_loc$vic40,out_loc$ur)
fisher.test(ct_out)
```

Yes it is, although the relationship is a little weaker outside Atlantida/Cortes than inside. So what have we learned here? If we take changing one's shopping habits as a proxy for fear of crime:

- Urban people in Atlantida/Cortes are more afraid than urban people elsewhere
- Rural people in Atlantida/Cortes aren't any more afraid than rural people elsewhere
- Urban people are more afraid than rural people, both inside and outside Atlantida/Cortes

In general, the urban/rural split is more important than whether people live in Atlantida/Cortes. However, the cities in those departments appear to be worse than the cities elsewhere in the country. We could follow up on this by repeating our analysis using `municipio` rather than `prov`, to see which municipalities have more fearful populations. I think this might be harder to map using googleVis, but the statistical analysis should be similar.
